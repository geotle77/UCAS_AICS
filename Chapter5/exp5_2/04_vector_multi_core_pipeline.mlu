// file: 04_vector_multi_core_pipeline.mlu

#include <bang.h>

#define ELEM_NUM 10 * 1000 * 1000
#define MAX_NRAM_SIZE 655360
#define NFU_ALIGN_SIZE 128

__nram__ uint8_t nram_buffer[MAX_NRAM_SIZE];

float src1_cpu[ELEM_NUM];
float src2_cpu[ELEM_NUM];
float dst_cpu[ELEM_NUM];

// load in pipeline
__mlu_func__ void L(float *a_ram, float *a, float *b_ram,
                    float *b, int data_ram_num, int i) {
  mluMemcpyDirection_t direction = GDRAM2NRAM;
  int offset = i % 2 * data_ram_num * 2;
  __memcpy_async(a_ram + offset, a + i * data_ram_num,
                 data_ram_num * sizeof(float), direction);
  __memcpy_async(b_ram + offset, b + i * data_ram_num,
                 data_ram_num * sizeof(float), direction);
}

// compute in pipeline
__mlu_func__ void C(float *a_ram, float *b_ram, int data_ram_num, int i) {
  int offset = i % 2 * data_ram_num * 2;
  __bang_add(a_ram + offset, a_ram + offset, b_ram + offset, data_ram_num);
}

// store in pipeline
__mlu_func__ void S(float *output, float *a_ram, int data_ram_num, int i) {
  mluMemcpyDirection_t direction = NRAM2GDRAM;
  int offset = i % 2 * data_ram_num * 2;
  __memcpy_async(output + i * data_ram_num, a_ram + offset,
  data_ram_num * sizeof(float), direction);
}

// load in pipeline
__mlu_func__ void L_rem(float *a_ram, float *a, float *b_ram, float *b,
                        int data_ram_num, int rem_ram_num, int loop_time,
                        int i) {
  mluMemcpyDirection_t direction = GDRAM2NRAM;
  int offset = i % 2 * data_ram_num * 2;
  __memcpy_async(a_ram + offset, a + loop_time * data_ram_num,
                 rem_ram_num * sizeof(float), direction);
  __memcpy_async(b_ram + offset, b + loop_time * data_ram_num,
                 rem_ram_num * sizeof(float), direction);
}

// compute in pipeline
__mlu_func__ void C_rem(float *a_ram, float *b_ram,
                        int data_ram_num, int rem_align_num, int i) {
  int offset = i % 2 * data_ram_num * 2;
  __bang_add(a_ram + offset, a_ram + offset, b_ram + offset, rem_align_num);
}

// store in pipeline
__mlu_func__ void S_rem(float *output, float *a_ram, int data_ram_num,
                        int rem_ram_num, int loop_time, int i) {
  mluMemcpyDirection_t direction = NRAM2GDRAM;
  int offset = i % 2 * data_ram_num * 2;
  __memcpy_async(output + loop_time * data_ram_num, a_ram + offset,
  rem_ram_num * sizeof(float), direction);
}

__mlu_func__ void add(float *output, float *a, float *b, int data_num) {
  if (data_num == 0) {
    return;
  }
  // ping: a(out), b || pong: a(out), b
  uint32_t align_num = NFU_ALIGN_SIZE / sizeof(float);
  uint32_t data_ram_num =
    MAX_NRAM_SIZE / sizeof(float) / 4 / align_num * align_num;
  float *a_ram = (float *)nram_buffer;
  float *b_ram = a_ram + data_ram_num;
  uint32_t loop_time = data_num / data_ram_num;
  uint32_t rem_ram_num = data_num % data_ram_num;
  int rem_num = 0;
  uint32_t rem_align_num =
    (rem_ram_num + align_num - 1) / align_num * align_num;
  if (rem_ram_num != 0) {
    rem_num = 1;
  }

  for (int i = 0; i < loop_time + 2 + rem_num; i++) {
    if (i >= 2) {
      // S(i - 2)
      if (i < loop_time + 2 + rem_num - 1 || rem_num == 0) {
        S(output, a_ram, data_ram_num, i - 2);
      } else if (rem_num == 1) {
       S_rem(output, a_ram, data_ram_num, rem_ram_num, loop_time, i - 2);
      }
    }
    if (i >= 1 && i < loop_time + 1 + rem_num) {
    // C(i - 1)
      if (i < loop_time + 1 + rem_num - 1 || rem_num == 0) {
        C(a_ram, b_ram, data_ram_num, i - 1);
      } else if (rem_num == 1) {
        C_rem(a_ram, b_ram, data_ram_num, rem_align_num, i - 1);
      }
    }
    if (i < loop_time + rem_num) {
    // L(i)
      if (i < loop_time + rem_num - 1 || rem_num == 0) {
        L(a_ram, a, b_ram, b, data_ram_num, i);
      } else if (rem_num == 1) {
        L_rem(a_ram, a, b_ram, b, data_ram_num, rem_ram_num, loop_time, i);
      }
    }
    __sync_all_ipu();
  }
  return;
}

__mlu_entry__ void kernel(float *output,
                          const float *a,
                          const float *b,
                          const int data_num) {
  // No need mpu core, return.
  if (coreId == 0x80) {
    return;
  }

  // TODO: 请补充BANG内置变量，获取并行任务总规模
  uint32_t task_dim = taskDim;
  // TODO: 请补充BANG内置变量，获取当前并行任务的索引
  uint32_t task_id = taskId;
  // TODO: 请补充计算每个核的计算数据量的表达式
  uint32_t data_per_core = data_num / task_dim;
  // TODO: 请补充当总数据量不能被并行任务总规模整除时，计算最后一个核数据量的表达式
  uint32_t data_last_core = data_num % task_dim ? data_num % task_dim : data_per_core;

  float *a_fix = (float *)a + task_id * data_per_core;
  float *b_fix = (float *)b + task_id * data_per_core;
  float *output_fix = (float *)output + task_id * data_per_core;

  if (task_id != task_dim - 1) {
    add(output_fix, a_fix, b_fix, data_per_core);
  } else {
    add(output_fix, a_fix, b_fix, data_last_core);
  }
}

void policyFunction(cnrtDim3_t *dim, cnrtFunctionType_t *func_type) {
  // TODO: 请补充多核Kernel任务的类型
  *func_type = CNRT_FUNC_TYPE_BLOCK;
  dim->x = 4;
  dim->y = 8;
  dim->z = 1;
  return;
}

int main() {
  CNRT_CHECK(cnrtSetDevice(0));
  cnrtNotifier_t st, et;
  CNRT_CHECK(cnrtNotifierCreate(&st));
  CNRT_CHECK(cnrtNotifierCreate(&et));
  cnrtQueue_t queue;
  CNRT_CHECK(cnrtQueueCreate(&queue));

  cnrtDim3_t dim;
  cnrtFunctionType_t func_type;
  policyFunction(&dim, &func_type);

  // 1.0f + 1.0f = 2.0f
  for (unsigned i = 0; i < ELEM_NUM; ++i) {
    src1_cpu[i] = 1.0f;
    src2_cpu[i] = 1.0f;
  }
  float* src1_mlu = NULL;
  float* src2_mlu = NULL;
  float* dst_mlu = NULL;
  CNRT_CHECK(cnrtMalloc((void **)&src1_mlu, ELEM_NUM * sizeof(float)));
  CNRT_CHECK(cnrtMalloc((void **)&src2_mlu, ELEM_NUM * sizeof(float)));
  CNRT_CHECK(cnrtMalloc((void **)&dst_mlu, ELEM_NUM * sizeof(float)));
  CNRT_CHECK(cnrtMemcpy(src1_mlu, src1_cpu, ELEM_NUM * sizeof(float),
                        cnrtMemcpyHostToDev));
  CNRT_CHECK(cnrtMemcpy(src2_mlu, src2_cpu, ELEM_NUM * sizeof(float),
                        cnrtMemcpyHostToDev));
  CNRT_CHECK(cnrtPlaceNotifier(st, queue));
  kernel<<<dim, func_type, queue>>>(dst_mlu, src1_mlu, src2_mlu, ELEM_NUM);
  CNRT_CHECK(cnrtPlaceNotifier(et, queue));
  CNRT_CHECK(cnrtQueueSync(queue));
  CNRT_CHECK(cnrtMemcpy(dst_cpu, dst_mlu, ELEM_NUM * sizeof(float),
                        cnrtMemcpyDevToHost));
  float latency;
  CNRT_CHECK(cnrtNotifierDuration(st, et, &latency));
  CNRT_CHECK(cnrtFree(src1_mlu));
  CNRT_CHECK(cnrtFree(src2_mlu));
  CNRT_CHECK(cnrtFree(dst_mlu));
  CNRT_CHECK(cnrtQueueDestroy(queue));

  float diff = 0.0;
  float baseline = 2.0;
  for (unsigned i = 0; i < ELEM_NUM; ++i) {
    diff += fabs(dst_cpu[i] - baseline);
  }
  double theory_io = ELEM_NUM * 4.0 * 3.0; // bytes
  double theory_ops = ELEM_NUM * 4.0; // ops
  // ops_per_core/ns * core_num_per_cluter * cluster_num
  double peak_compute_force = 128 * 4 * 8;
  double io_bandwidth = 307.2; // bytes/ns
  double io_efficiency = theory_io / (latency * 1000) / io_bandwidth;
  double cp_efficiency = theory_ops / (latency * 1000) / peak_compute_force;
  printf("[MLU Hardware Time ]: %.3f us\n", latency);
  printf("[MLU IO Efficiency ]: %f\n", io_efficiency);
  printf("[MLU Compute Efficiency]: %f\n", cp_efficiency);
  printf("[MLU Diff Rate ]: %f\n", diff);
  printf(diff == 0 ? "PASSED\n" : "FAILED\n");

  return 0;
}
